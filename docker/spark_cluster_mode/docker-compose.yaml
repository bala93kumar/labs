
services:
  spark-master:
    image: spark:3.5.7-python3
    container_name: spark-master
    environment:
      - SPARK_LOCAL_IP=spark-master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master",
              "--host", "spark-master", "--port", "7077", "--webui-port", "8080"]
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./events:/opt/spark-events
      - ./conf:/opt/spark/conf
    networks: [spark-net]
    # ---- Host cgroup limits ----
    cpus: 1.0
    mem_limit: 2g

  spark-worker-1:
    image: spark:3.5.7-python3
    container_name: spark-worker-1
    depends_on: [spark-master]
    environment:
      - SPARK_LOCAL_IP=spark-worker-1
      # Spark scheduling caps (must fit under mem_limit/cpus):
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=6g
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker",
              "spark://spark-master:7077"]
    volumes:
      - ./data:/opt/data
      - ./events:/opt/spark-events
      - ./conf:/opt/spark/conf
      - ./output:/opt/output
    networks: [spark-net]
    # ---- Host cgroup limits ----
    cpus: 4.0
    mem_limit: 7g     # gives some overhead above SPARK_WORKER_MEMORY

  spark-worker-2:
    image: spark:3.5.7-python3
    container_name: spark-worker-2
    depends_on: [spark-master]
    environment:
      - SPARK_LOCAL_IP=spark-worker-2
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=6g
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker",
              "spark://spark-master:7077"]
    volumes:
      - ./data:/opt/data
      - ./events:/opt/spark-events
      - ./conf:/opt/spark/conf
      - ./output:/opt/output
    networks: [spark-net]
    # ---- Host cgroup limits ----
    cpus: 4.0
    mem_limit: 7g

  # Optional third worker for more throughput:
  # spark-worker-3:
  #   image: spark:3.5.7-python3
  #   container_name: spark-worker-3
  #   depends_on: [spark-master]
  #   environment:
  #     - SPARK_LOCAL_IP=spark-worker-3
  #     - SPARK_WORKER_CORES=4
  #     - SPARK_WORKER_MEMORY=6g
  #   command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker",
  #             "spark://spark-master:7077"]
  #   volumes:
  #     - ./events:/opt/spark-events
  #     - ./conf:/opt/spark/conf
  #   networks: [spark-net]
  #   cpus: 4.0
  #   mem_limit: 7g

  spark-history:
    image: spark:3.5.7-python3
    container_name: spark-history
    depends_on: [spark-master]
    ports:
      - "18080:18080"
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark-events -Dspark.history.ui.port=18080
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.history.HistoryServer"]
    volumes:
      - ./events:/opt/spark-events
      - ./conf:/opt/spark/conf
    networks: [spark-net]
    # ---- Host cgroup limits ----
    cpus: 0.5
    mem_limit: 1g

  spark-client:
    image: spark:3.5.7-python3
    container_name: spark-client
    environment:
      - PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/spark/bin
      - SPARK_LOCAL_IP=spark-client
    command: ["bash", "-lc", "sleep infinity"]
    ports:
      - "4040:4040"
    volumes:
      - ./src:/opt/app
      - ./data:/opt/data
      - ./output:/opt/output
      - ./events:/opt/spark-events
      - ./conf:/opt/spark/conf
    networks: [spark-net]
    # ---- Host cgroup limits ----
    cpus: 2.0
    mem_limit: 4g

networks:
  spark-net:
    driver: bridge